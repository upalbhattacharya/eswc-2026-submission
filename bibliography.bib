@comment{
ebib-main-file: /home/workboots/References/main.bib
}


@inproceedings{tsaneva2024LlmDrivenOntology,
	file = {References/pdf/tsaneva2024LlmDrivenOntology.pdf},
	author = {Stefani Tsaneva and Stefan Vasic and Marta Sabou},
	title = {LLM-driven Ontology Evaluation: Verifying Ontology
                  Restrictions with ChatGPT},
	year = 2024,
	booktitle = {Joint proceedings of the 3rd International workshop
                  on knowledge graph generation from text {(TEXT2KG)}
                  and Data Quality meets Machine Learning and
                  Knowledge Graphs {(DQMLKG)} co-located with the
                  Extended Semantic Web Conference {(} {ESWC} 2024),
                  Hersonissos, Greece, May 26-30, 2024},
	pages = 15,
	url = {https://ceur-ws.org/Vol-3747/dqmlkg\_paper3.pdf},
	crossref = {DBLP:conf/text2kg/2024},
	timestamp = {Thu, 31 Oct 2024 17:18:55 +0100},
	biburl = {https://dblp.org/rec/conf/text2kg/TsanevaVS24.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@inproceedings{evans2003FrameworkNamedEntity,
	file = {References/pdf/evans2003FrameworkNamedEntity.pdf},
	author = {Richard J. Evans},
	title = {A framework for named entity recognition in the open
                  domain},
	year = 2003,
	booktitle = {Recent Advances in Natural Language Processing III,
                  Selected Papers from {RANLP} 2003, Borovets,
                  Bulgaria},
	pages = {267-276},
	crossref = {DBLP:conf/ranlp/2003},
	timestamp = {Tue, 22 Feb 2005 13:47:43 +0100},
	biburl = {https://dblp.org/rec/conf/ranlp/Evans03.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{ashburner2000GeneOntologyTool,
	title = {Gene {{Ontology}}: {{Tool}} for the Unification of Biology},
	shorttitle = {Gene {{Ontology}}},
	author = {Ashburner, Michael and Ball, Catherine A. and Blake, Judith A. and Botstein, David and Butler, Heather and Cherry, J. Michael and Davis, Allan P. and Dolinski, Kara and Dwight, Selina S. and Eppig, Janan T. and Harris, Midori A. and Hill, David P. and Issel-Tarver, Laurie and Kasarskis, Andrew and Lewis, Suzanna and Matese, John C. and Richardson, Joel E. and Ringwald, Martin and Rubin, Gerald M. and Sherlock, Gavin},
	date = {2000-05},
	journal = {Nature Genetics},
	volume = {25},
	number = {1},
	pages = {25--29},
	publisher = {Nature Publishing Group},
	issn = {1546-1718},
	doi = {10.1038/75556},
	abstract = {Genomic sequencing has made it clear that a large fraction of the genes specifying the core biological functions are shared by all eukaryotes. Knowledge of the biological role of such shared proteins in one organism can often be transferred to other organisms. The goal of the Gene Ontology Consortium is to produce a dynamic, controlled vocabulary that can be applied to all eukaryotes even as knowledge of gene and protein roles in cells is accumulating and changing. To this end, three independent ontologies accessible on the World-Wide Web (http://www.geneontology.org) are being constructed: biological process, molecular function and cellular component.},
	copyright = {2000 Nature America Inc.},
	langid = {english},
	keywords = {Agriculture,Animal Genetics and Genomics,Biomedicine,Cancer Research,Gene Function,general,Human Genetics},
	timestamp = {2024-09-12T13:49:25Z},
	file = {References/pdf/ashburner2000GeneOntologyTool.pdf}
}

@article{asim2018SurveyOntologyLearning,
	file = {References/pdf/asim2018SurveyOntologyLearning.pdf},
	title = {A Survey of Ontology Learning Techniques and Applications},
	author = {Asim, Muhammad Nabeel and Wasim, Muhammad and Khan, Muhammad Usman Ghani and Mahmood, Waqar and Abbasi, Hafiza Mahnoor},
	date = {2018},
        year = 2018,
	journal = {Database, The Journal of Biological Databases and Curation},
	volume = {2018},
	pages = {1--24},
	publisher = {Oxford University Press},
	doi = {10.1093/database/bay101}
}

@inproceedings{babaei2023Llms4olLargeLanguage,
	title = {{{LLMs4OL}}: {{Large Language Models}} for {{Ontology Learning}}},
	shorttitle = {{{LLMs4OL}}},
	booktitle = {The {{Semantic Web}} – {{ISWC}} 2023},
	author = {Babaei Giglou, Hamed and D'Souza, Jennifer and Auer, Sören},
	editor = {Payne, Terry R. and Presutti, Valentina and Qi, Guilin and Poveda-Villalón, María and Stoilos, Giorgos and Hollink, Laura and Kaoudi, Zoi and Cheng, Gong and Li, Juanzi},
	date = {2023},
        year = 2023,
	pages = {408--427},
	publisher = {Springer Nature Switzerland},
	location = {Cham},
	doi = {10.1007/978-3-031-47240-4_22},
	abstract = {We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs) for Ontology Learning (OL). LLMs have shown significant advancements in natural language processing, demonstrating their ability to capture complex language patterns in different knowledge domains. Our LLMs4OL paradigm investigates the following hypothesis: Can LLMs effectively apply their language pattern capturing capability to OL, which involves automatically extracting and structuring knowledge from natural language text? To test this hypothesis, we conduct a comprehensive evaluation using the zero-shot prompting method. We evaluate nine different LLM model families for three main OL tasks: term typing, taxonomy discovery, and extraction of non-taxonomic relations. Additionally, the evaluations encompass diverse genres of ontological knowledge, including lexicosemantic knowledge in WordNet, geographical knowledge in GeoNames, and medical knowledge in UMLS.},
	isbn = {978-3-031-47240-4},
	langid = {english},
	keywords = {Important,Large Language Models,LLMs,Ontologies,Ontology Learning,Prompt-based Learning,Prompting},
	timestamp = {2024-09-12T12:01:26Z},
	file = {References/pdf/babaei2023Llms4olLargeLanguage.pdf}
}

@inbook{babaei2025Llms4omMatchingOntologies,
	file = {References/pdf/babaei2025Llms4omMatchingOntologies.pdf},
	title = {LLMs4OM: Matching Ontologies with Large Language
                  Models},
	year = 2025,
	author = {Babaei Giglou, Hamed and D’Souza, Jennifer and
                  Engel, Felix and Auer, Sören},
	booktitle = {The Semantic Web: ESWC 2024 Satellite Events},
	publisher = {Springer Nature Switzerland},
	isbn = 9783031789526,
	pages = {25–35},
	doi = {10.1007/978-3-031-78952-6_3},
	url = {http://dx.doi.org/10.1007/978-3-031-78952-6_3},
	ISSN = {1611-3349}
}

@book{baezayates1999ModernInformationRetrieval,
	file = {References/pdf/baezayates1999ModernInformationRetrieval.pdf},
	title = {Modern Information Retrieval},
	author = {Baeza-Yates, Ricardo and Ribeiro-Neto, Berthier and others},
	date = {1999},
        year = 1999,
	volume = {463},
	publisher = {ACM press New York}
}

@article{bakker2024DynamicKnowledgeGraph,
	file = {References/pdf/bakker2024DynamicKnowledgeGraph.pdf},
	title = {Dynamic Knowledge Graph Evaluation},
	author = {Bakker, Roos M and De Boer, Maaike HT},
	date = {2024},
        year  = 2024,
	journal = {Authorea Preprints},
	publisher = {Authorea}
}

@inproceedings{bakker2024TextKnowledgeGraph,
	file = {References/pdf/bakker2024TextKnowledgeGraph.pdf},
	title = {From Text to Knowledge Graph: {{Comparing}} Relation Extraction Methods in a Practical Context},
	booktitle = {First International Workshop on Generative Neuro-Symbolic {{AI}}, Co-Located with {{ESWC}}},
	author = {Bakker, Roos M and Di Scala, Daan L},
	date = {2024},
        year = 2024,
	volume = {4},
	pages = {7}
}

@incollection{bashir2017RetrievalModelsVersus,
	title = {Retrieval {{Models Versus Retrievability}}},
	booktitle = {Current {{Challenges}} in {{Patent Information Retrieval}}},
	author = {Bashir, Shariq and Rauber, Andreas},
	editor = {Lupu, Mihai and Mayer, Katja and Kando, Noriko and Trippe, Anthony J.},
	date = {2017},
	pages = {185--212},
	publisher = {Springer},
	location = {Berlin, Heidelberg},
	doi = {10.1007/978-3-662-53817-3_7},
	abstract = {Retrievability is an important measure in information retrieval (IR) that can be used to analyse retrieval models and document collections. Rather than just focusing on a set of few documents that are given in the form of relevance judgements, retrievability examines what is retrieved, how frequently it is retrieved and how much effort is needed to retrieve it. Such a measure is of particular interest within the recall-oriented retrieval systems (e.g. patent or legal retrieval), because in this context a document needs to be retrieved before it can be judged for relevance. If a retrieval model makes some patents hard to find, patent searchers could miss relevant documents just because of the bias of the retrieval model. In this chapter we explain the concept of retrievability in information retrieval. We also explain how it can be estimated and how it can be used for analysing a retrieval bias of retrieval models. We also show how retrievability relates to effectiveness by analysing the relationship between retrievability and effectiveness measures and how the retrievability measure can be used to improve effectiveness.},
	isbn = {978-3-662-53817-3},
	langid = {english},
	timestamp = {2024-09-12T22:42:53Z},
	file = {References/pdf/bashir2017RetrievalModelsVersus.pdf}
}

@misc{bombieri2024DoLlmsDream,
	title = {Do {{LLMs Dream}} of {{Ontologies}}?},
	author = {Bombieri, Marco and Fiorini, Paolo and Ponzetto, Simone Paolo and Rospocher, Marco},
	date = {2024-01},
        year = 2024,
	eprint = {2401.14931},
	eprinttype = {arXiv},
	eprintclass = {cs},
	doi = {10.48550/arXiv.2401.14931},
	abstract = {Large language models (LLMs) have recently revolutionized automated text understanding and generation. The performance of these models relies on the high number of parameters of the underlying neural architectures, which allows LLMs to memorize part of the vast quantity of data seen during the training. This paper investigates whether and to what extent general-purpose pre-trained LLMs have memorized information from known ontologies. Our results show that LLMs partially know ontologies: they can, and do indeed, memorize concepts from ontologies mentioned in the text, but the level of memorization of their concepts seems to vary proportionally to their popularity on the Web, the primary source of their training material. We additionally propose new metrics to estimate the degree of memorization of ontological information in LLMs by measuring the consistency of the output produced across different prompt repetitions, query languages, and degrees of determinism.},
	organization = {arXiv},
	keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
	timestamp = {2024-07-25T09:04:21Z},
	file = {References/pdf/bombieri2024DoLlmsDream.pdf}
}

@article{bommasani2023HolisticEvaluationLanguage,
	file = {References/pdf/bommasani2023HolisticEvaluationLanguage.pdf},
	author = {Bommasani, Rishi and Liang, Percy and Lee, Tony},
	title = {Holistic Evaluation of Language Models},
	journal = {Annals of the New York Academy of Sciences},
	year = 2023,
	volume = 1525,
	number = 1,
	month = may,
	pages = {140–146},
	issn = {1749-6632},
	doi = {10.1111/nyas.15007},
	url = {http://dx.doi.org/10.1111/nyas.15007},
	publisher = {Wiley}
}

@inproceedings{brank2005SurveyOntologyEvaluation,
	file = {References/pdf/brank2005SurveyOntologyEvaluation.pdf},
	title = {A Survey of Ontology Evaluation Techniques},
	booktitle = {Proceedings of the Conference on Data Mining and Data Warehouses ({{SiKDD}} 2005)},
	author = {Brank, Janez and Grobelnik, Marko and Mladenic, Dunja},
	date = {2005},
        year = 2005,
	pages = {166--170},
	publisher = {Citeseer}
}

@inproceedings{buitelaar2005OntologyLearningText,
	keywords = {ontology},
	file = {References/pdf/buitelaar2005OntologyLearningText.pdf},
	url = {https://core.ac.uk/download/pdf/15992822.pdf},
	year = 2005,
	title = {Ontology Learning from Text: An Overview},
	author = {Paul Buitelaar and Philipp Cimiano and Bernardo Magnini}
}

@article{carlini2022QuantifyingMemorizationAcross,
	file = {References/pdf/carlini2022QuantifyingMemorizationAcross.pdf},
	title = {Quantifying {{Memorization Across Neural Language Models}}},
	author = {Carlini, Nicholas and Ippolito, Daphne and Jagielski, Matthew and Lee, Katherine and Tramèr, Florian and Zhang, Chiyuan},
	date = {2022-02},
	journal = {ArXiv},
	abstract = {Large language models (LMs) have been shown to memorize parts of their training data, and when prompted appropriately, they will emit the memorized training data verbatim. This is undesirable because memorization violates privacy (exposing user data), degrades utility (repeated easy-to-memorize text is often low quality), and hurts fairness (some texts are memorized over others). We describe three log-linear relationships that quantify the degree to which LMs emit memorized training data. Memorization significantly grows as we increase (1) the capacity of a model, (2) the number of times an example has been duplicated, and (3) the number of tokens of context used to prompt the model. Surprisingly, we find the situation becomes more complicated when generalizing these results across model families. On the whole, we find that memorization in LMs is more prevalent than previously believed and will likely get worse as models continues to scale, at least without active mitigations.},
	timestamp = {2024-09-12T16:30:35Z}
}

@article{casey2017AdvancingCoordinatedCyber,
	title = {Advancing Coordinated Cyber-Investigations and Tool Interoperability Using a Community Developed Specification Language},
	author = {Casey, Eoghan and Barnum, Sean and Griffith, Ryan and Snyder, Jonathan and Van Beek, Harm and Nelson, Alex},
	date = {2017-09},
        year = 2017,
	journal = {Digital Investigation},
	volume = {22},
	pages = {14--45},
	issn = {17422876},
	doi = {10.1016/j.diin.2017.08.002},
	abstract = {Any investigation can have a digital dimension, often involving information from multiple data sources, organizations and jurisdictions. Existing approaches to representing and exchanging cyber-investigation information are inadequate, particularly when combining data sources from numerous organizations or dealing with large amounts of data from various tools. To perform digital investigations effectively, there is a pressing need to harmonize how information relevant to cyber-investigations is represented and exchanged. This paper addresses this need for information exchange and tool interoperability with an open community-developed specification language called Cyber-investigation Analysis Standard Expression (CASE). To further promote a common structure, CASE aligns with and extends the Unified Cyber Ontology (UCO) construct, which provides a format for representing information in all cyber domains. This ontology abstracts objects and concepts that are not CASE-specific, so that they can be used across other cyber disciplines that may extend UCO. This work is a rational evolution of the Digital Forensic Analysis eXpression (DFAX) for representing digital forensic information and provenance. CASE is more flexible than DFAX and can be utilized in any context, including criminal, corporate and intelligence. CASE also builds on the Hansken data model developed and implemented by the Netherlands Forensic Institute (NFI). CASE enables the fusion of information from different organizations, data sources, and forensic tools to foster more comprehensive and cohesive analysis. This paper includes illustrative examples of how CASE can be implemented and used to capture information in a structured form to advance sharing, interoperability and analysis in cyber-investigations. In addition to capturing technical details and relationships between objects, CASE provides structure for representing and sharing details about how cyber-information was handled, transferred, processed, analyzed, and interpreted. CASE also supports data marking for sharing information at different levels of trust and classification, as well as protection of sensitive and private information. Furthermore, CASE supports the sharing of knowledge related to cyber-investigations, including distinctive patterns of activity/behavior that are common across cases. This paper features a proof-of-concept implementation using the open source forensic framework named plaso to export data to CASE. Community members are encouraged to participate in the development and implementation of CASE and UCO.},
	langid = {english},
	timestamp = {2024-09-12T21:23:56Z},
	file = {References/pdf/casey2017AdvancingCoordinatedCyber.pdf}
}

@incollection{casey2018EvolutionExpressingExchanging,
	title = {The {{Evolution}} of {{Expressing}} and {{Exchanging Cyber-Investigation Information}} in a {{Standardized Form}}},
	booktitle = {Handling and {{Exchanging Electronic Evidence Across Europe}}},
	author = {Casey, Eoghan and Barnum, Sean and Griffith, Ryan and Snyder, Jonathan and family=Beek, given=Harm, prefix=van, useprefix=true and Nelson, Alex},
	editor = {Biasiotti, Maria Angela and Mifsud Bonnici, Jeanne Pia and Cannataci, Joe and Turchi, Fabrizio},
	date = {2018},
	pages = {43--58},
	publisher = {Springer International Publishing},
	location = {Cham},
	doi = {10.1007/978-3-319-74872-6_4},
	abstract = {The growing number of investigations involving digital traces from various data sources is driving the demand for a standard way to represent and exchange pertinent information. Enabling automated combination and correlation of cyber-investigation information from multiple systems or organizations enables more efficient and comprehensive analysis, reducing the risk of mistakes and missed opportunities. These needs are being met by the evolving open-source, community-developed specification language called CASE, the Cyber-investigation Analysis Standard Expression. CASE leverages the Unified Cyber Ontology (UCO), which abstracts and expresses concepts that are common across multiple domains. This paper introduces CASE and UCO, explaining how they improve upon prior related work. The value of fully-structured data, representing provenance, and action lifecycles are discussed. The guiding principles of CASE and UCO are presented, and illustrative examples of CASE are provided using the default JSON-LD serialization.},
	isbn = {978-3-319-74872-6},
	langid = {english},
	keywords = {Cyber Investigators,Digital Evidence,Digital Forensics,Full Data Structure,National Software Reference Library (NSRL)},
	timestamp = {2024-09-12T17:52:06Z},
	file = {References/pdf/casey2018EvolutionExpressingExchanging.pdf}
}

@article{caufield2024StructuredPromptInterrogation,
	file = {References/pdf/caufield2024StructuredPromptInterrogation.pdf},
	title = {Structured Prompt Interrogation and Recursive Extraction of Semantics ({{SPIRES}}): {{A}} Method for Populating Knowledge Bases Using Zero-Shot Learning},
	author = {Caufield, J Harry and Hegde, Harshad and Emonet, Vincent and Harris, Nomi L and Joachimiak, Marcin P and Matentzoglu, Nicolas and Kim, HyeongSik and Moxon, Sierra and Reese, Justin T and Haendel, Melissa A and others},
	date = {2024},
        year = 2024,
	journal = {Bioinformatics (Oxford, England)},
	shortjournal = {Bioinformatics},
	volume = {40},
	number = {3},
	pages = {btae104},
	publisher = {Oxford University Press}
}

@article{chen2023ContextualSemanticEmbeddings,
	file = {References/pdf/chen2023ContextualSemanticEmbeddings.pdf},
	title = {Contextual Semantic Embeddings for Ontology Subsumption Prediction},
	author = {Chen, Jiaoyan and He, Yuan and Geng, Yuxia and Jiménez-Ruiz, Ernesto and Dong, Hang and Horrocks, Ian},
	date = {2023-09},
    year = 2023,
	journal = {World Wide Web-internet and Web Information Systems},
	shortjournal = {World Wide Web},
	volume = {26},
	number = {5},
	pages = {2569--2591},
	issn = {1573-1413},
	doi = {10.1007/s11280-023-01169-9},
	abstract = {Automating ontology construction and curation is an important but challenging task in knowledge engineering and artificial intelligence. Prediction by machine learning techniques such as contextual semantic embedding is a promising direction, but the relevant research is still preliminary especially for expressive ontologies in Web Ontology Language (OWL). In this paper, we present a new subsumption prediction method named BERTSubs for classes of OWL ontology. It exploits the pre-trained language model BERT to compute contextual embeddings of a class, where customized templates are proposed to incorporate the class context (e.g., neighbouring classes) and the logical existential restriction. BERTSubs is able to predict multiple kinds of subsumers including named classes from the same ontology or another ontology, and existential restrictions from the same ontology. Extensive evaluation on five real-world ontologies for three different subsumption tasks has shown the effectiveness of the templates and that BERTSubs can dramatically outperform the baselines that use (literal-aware) knowledge graph embeddings, non-contextual word embeddings and the state-of-the-art OWL ontology embeddings.},
	langid = {english},
	keywords = {Artificial Intelligence,BERT,Ontology alignment,Ontology embedding,OWL,Pre-trained language model,Subsumption prediction},
	timestamp = {2024-08-15T09:49:42Z}
}

@inproceedings{devlin2019BertPreTraining,
	file = {References/pdf/devlin2019BertPreTraining.pdf},
	title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
	shorttitle = {{{BERT}}},
	booktitle = {Proceedings of the 2019 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}, {{Volume}} 1 ({{Long}} and {{Short Papers}})},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	editor = {Burstein, Jill and Doran, Christy and Solorio, Thamar},
	date = {2019-06},
	pages = {4171--4186},
	publisher = {Association for Computational Linguistics},
	location = {Minneapolis, Minnesota},
	doi = {10.18653/v1/N19-1423},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	timestamp = {2024-09-12T10:18:35Z}
}

@inproceedings{dong2024LanguageModelBased,
	file = {References/pdf/dong2024LanguageModelBased.pdf},
	title = {A {{Language Model Based Framework}} for {{New Concept Placement}} in {{Ontologies}}},
	booktitle = {The {{Semantic Web}}},
	author = {Dong, Hang and Chen, Jiaoyan and He, Yuan and Gao, Yongsheng and Horrocks, Ian},
	editor = {Meroño Peñuela, Albert and Dimou, Anastasia and Troncy, Raphaël and Hartig, Olaf and Acosta, Maribel and Alam, Mehwish and Paulheim, Heiko and Lisena, Pasquale},
	date = {2024},
    year = 2024,
	pages = {79--99},
	publisher = {Springer Nature Switzerland},
	location = {Cham},
	doi = {10.1007/978-3-031-60626-7_5},
	abstract = {We investigate the task of inserting new concepts extracted from texts into an ontology using language models. We explore an approach with three steps: edge search which is to find a set of candidate locations to insert (i.e., subsumptions between concepts), edge formation and enrichment which leverages the ontological structure to produce and enhance the edge candidates, and edge selection which eventually locates the edge to be placed into. In all steps, we propose to leverage neural methods, where we apply embedding-based methods and contrastive learning with Pre-trained Language Models (PLMs) such as BERT for edge search, and adapt a BERT fine-tuning-based multi-label Edge-Cross-encoder, and Large Language Models (LLMs) such as GPT series, FLAN-T5, and Llama 2, for edge selection. We evaluate the methods on recent datasets created using the SNOMED CT ontology and the MedMentions entity linking benchmark. The best settings in our framework use fine-tuned PLM for search and a multi-label Cross-encoder for selection. Zero-shot prompting of LLMs is still not adequate for the task, and we propose explainable instruction tuning of LLMs for improved performance. Our study shows the advantages of PLMs and highlights the encouraging performance of LLMs that motivates future studies.},
	isbn = {978-3-031-60626-7},
	langid = {english},
	keywords = {Concept Placement,Large Language Models,Ontology Enrichment,Pre-trained Language Models,SNOMED CT},
	timestamp = {2024-08-15T09:20:01Z}
}

@inproceedings{doumanas2024IntegratingLlmsIn,
	file = {References/pdf/doumanas2024IntegratingLlmsIn.pdf},
	title = {Integrating {{LLMs}} in the {{Engineering}} of a {{SAR Ontology}}},
	booktitle = {Artificial {{Intelligence Applications}} and {{Innovations}}},
	author = {Doumanas, Dimitrios and Soularidis, Andreas and Kotis, Konstantinos and Vouros, George},
	editor = {Maglogiannis, Ilias and Iliadis, Lazaros and Macintyre, John and Avlonitis, Markos and Papaleonidas, Antonios},
	date = {2024},
	pages = {360--374},
	publisher = {Springer Nature Switzerland},
	location = {Cham},
	doi = {10.1007/978-3-031-63223-5_27},
	abstract = {In Search and Rescue (SAR) missions, the integration of multiple sources of information may enhance operational efficiency and increase responsiveness significantly, improving situation awareness and aiding decision-making to save lives and mitigate incident impact. Ontologies are crucial for integrating and reasoning with data from diverse sources. Engineering a domain ontology for SAR can be better supported from an agile, collaborative, and iterative ontology engineering methodology (OEM), incorporating the interests of several stakeholders. Large Language Models (LLMs) can play a significant role in completing OEM processes. The goal of this work is to identify how ontology engineering (OE) tasks can be completed with the collaboration of LLMs and humans. The objectives of this paper are, a) to present preliminary exploration of LLMs to generate domain ontologies for the modeling of SAR missions in wildfire incidents b) to propose and evaluate an LLM-enhanced OE approach. In overall, the main contribution of the work presented in this paper is the analysis of LLMs capabilities to ontology engineering, and the evaluation of the synergy between humans and machines to efficiently represent knowledge, with specific focus in the SAR domain.},
	isbn = {978-3-031-63223-5},
	langid = {english},
	keywords = {Large Language Models,Ontology Engineering,Search and Rescue},
	timestamp = {2024-09-12T09:47:07Z}
}

@misc{du2024ShortReviewOntology,
	keywords = {ontology, llm, review},
	file = {References/pdf/du2024ShortReviewOntology.pdf},
	author = {Rick Du AND Huilong An AND Keyu Wang AND Weidong
                  Liu},
	title = {{A Short Review for Ontology Learning: Stride to
                  Large Language Models Trend}},
	year = 2024,
	eprint = {2404.14991v2},
	primaryclass = {cs.IR},
	archiveprefix = {arXiv}
}

@inproceedings{etzioni2004WebScaleInformation,
	file = {References/pdf/etzioni2004WebScaleInformation.pdf},
	author = {Etzioni, Oren and Cafarella, Michael and Downey,
                  Doug and Kok, Stanley and Popescu, Ana-Maria and
                  Shaked, Tal and Soderland, Stephen and Weld, Daniel
                  S. and Yates, Alexander},
	title = {Web-scale information extraction in knowitall:
                  (preliminary results)},
	year = 2004,
	booktitle = {Proceedings of the 13th international conference on
                  World Wide Web},
	series = {WWW04},
	publisher = {ACM},
	month = may,
	pages = {100–110},
	doi = {10.1145/988672.988687},
	url = {http://dx.doi.org/10.1145/988672.988687},
	collection = {WWW04}
}

@inproceedings{funk2023TowardsOntologyConstruction,
	file = {References/pdf/funk2023TowardsOntologyConstruction.pdf},
	title = {Towards {{Ontology Construction}} with {{Language Models}}},
	booktitle = {{{KBC-LM}} @ {{ISWC}} 2023},
	author = {Funk, Maurice and Hosemann, Simon and Jung, Jean Christoph and Lutz, Carsten},
	date = {2023},
    year = 2023,
	doi = {10.48550/arXiv.2309.09898},
	abstract = {An academic search engine that utilizes artificial intelligence methods to provide highly relevant results and novel tools to filter them with ease.},
	langid = {english},
	timestamp = {2024-07-25T09:10:54Z}
}

@article{gangemi2005OntologyEvaluationValidation,
	file = {References/pdf/gangemi2005OntologyEvaluationValidation.pdf},
	title = {Ontology Evaluation and Validation: An Integrated Formal Model for the Quality Diagnostic Task},
	author = {Gangemi, Aldo and Catenacci, Carola and Ciaramita, Massimiliano and Lehmann, Jens},
	date = {2005},
        year = 2005,
	journal = {On-line: http://www. loa-cnr. it/Files/OntoEval4OntoDev\_Final. pdf}
}

@misc{giglou2024Llms4ol2024Overview,
	keywords = {ontology, llm},
	file = {References/pdf/giglou2024Llms4ol2024Overview.pdf},
	author = {Hamed Babaei Giglou AND Jennifer D'Souza AND Sören
                  Auer},
	title = {{LLMs4OL 2024 Overview: The 1st Large Language
                  Models for Ontology Learning Challenge}},
	year = 2024,
	eprint = {2409.10146v1},
	primaryclass = {cs.CL},
	archiveprefix = {arXiv}
}

@inproceedings{hao2023BertnetHarvestingKnowledge,
	file = {References/pdf/hao2023BertnetHarvestingKnowledge.pdf},
	author = {Hao, Shibo and Tan, Bowen and Tang, Kaiwen and Ni,
                  Bin and Shao, Xiyan and Zhang, Hengzhe and Xing,
                  Eric and Hu, Zhiting},
	title = {BertNet: Harvesting Knowledge Graphs with Arbitrary
                  Relations from Pretrained Language Models},
	year = 2023,
	booktitle = {Findings of the Association for Computational
                  Linguistics: ACL 2023},
	publisher = {Association for Computational Linguistics},
	doi = {10.18653/v1/2023.findings-acl.309},
	url = {http://dx.doi.org/10.18653/v1/2023.findings-acl.309}
}

@article{he2022BertmapBertBased,
	file = {References/pdf/he2022BertmapBertBased.pdf},
	title = {{{BERTMap}}: {{A BERT-Based Ontology Alignment System}}},
	shorttitle = {{{BERTMap}}},
	author = {He, Yuan and Chen, Jiaoyan and Antonyrajah, Denvar and Horrocks, Ian},
	date = {2022-06},
    year = 2022,
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume = {36},
	number = {5},
	pages = {5684--5691},
	issn = {2374-3468, 2159-5399},
	doi = {10.1609/aaai.v36i5.20510},
	abstract = {Ontology alignment (a.k.a ontology matching (OM)) plays a critical role in knowledge integration. Owing to the success of machine learning in many domains, it has been applied in OM. However, the existing methods, which often adopt adhoc feature engineering or non-contextual word embeddings, have not yet outperformed rule-based systems especially in an unsupervised setting. In this paper, we propose a novel OM system named BERTMap which can support both unsupervised and semi-supervised settings. It first predicts mappings using a classifier based on fine-tuning the contextual embedding model BERT on text semantics corpora extracted from ontologies, and then refines the mappings through extension and repair by utilizing the ontology structure and logic. Our evaluation with three alignment tasks on biomedical ontologies demonstrates that BERTMap can often perform better than the leading OM systems LogMap and AML.},
	langid = {english},
	timestamp = {2024-07-25T09:06:38Z}
}

@inproceedings{he2023ExploringLargeLanguage,
	file = {References/pdf/he2023ExploringLargeLanguage.pdf},
	title = {Exploring Large Language Models for Ontology Alignment},
	booktitle = {Proceedings of the {{ISWC}} 2023 Posters, Demos and Industry Tracks: {{From}} Novel Ideas to Industrial Practice Co-Located with 22nd International Semantic Web Conference ({{ISWC}} 2023), Athens, Greece, November 6-10, 2023},
	author = {He, Yuan and Chen, Jiaoyan and Dong, Hang and Horrocks, Ian},
	editor = {Fundulaki, Irini and Kozaki, Kouji and Garijo, Daniel and Gómez-Pérez, José Manuél},
	date = {2023},
    year = 2023,
	series = {{{CEUR}} Workshop Proceedings},
	volume = {3632},
	publisher = {CEUR-WS.org},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	timestamp = {Mon, 03 Jun 2024 15:23:14 +0200}
}

@inproceedings{he2023LanguageModelAnalysis,
	file = {References/pdf/he2023LanguageModelAnalysis.pdf},
	title = {Language {{Model Analysis}} for {{Ontology Subsumption Inference}}},
	booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{ACL}} 2023},
	author = {He, Yuan and Chen, Jiaoyan and Jimenez-Ruiz, Ernesto and Dong, Hang and Horrocks, Ian},
	editor = {Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
	date = {2023-07},
    year = 2023,
	pages = {3439--3453},
	publisher = {Association for Computational Linguistics},
	location = {Toronto, Canada},
	doi = {10.18653/v1/2023.findings-acl.213},
	abstract = {Investigating whether pre-trained language models (LMs) can function as knowledge bases (KBs) has raised wide research interests recently. However, existing works focus on simple, triple-based, relational KBs, but omit more sophisticated, logic-based, conceptualised KBs such as OWL ontologies. To investigate an LM's knowledge of ontologies, we propose OntoLAMA, a set of inference-based probing tasks and datasets from ontology subsumption axioms involving both atomic and complex concepts. We conduct extensive experiments on ontologies of different domains and scales, and our results demonstrate that LMs encode relatively less background knowledge of Subsumption Inference (SI) than traditional Natural Language Inference (NLI) but can improve on SI significantly when a small number of samples are given. We will open-source our code and datasets.},
	timestamp = {2024-08-15T09:50:24Z}
}

@article{hlomani2014ApproachesMethodsMetrics,
	file = {References/pdf/hlomani2014ApproachesMethodsMetrics.pdf},
	title = {Approaches, Methods, Metrics, Measures, and Subjectivity in Ontology Evaluation: {{A}} Survey},
	author = {Hlomani, Hlomani and Stacey, Deborah},
	date = {2014},
        year = 2014,
	journal = {Semantic Web Journal},
	volume = {1},
	number = {5},
	pages = {1--11}
}

@misc{kaplan2020ScalingLawsNeural,
	file = {References/pdf/kaplan2020ScalingLawsNeural.pdf},
	title = {Scaling {{Laws}} for {{Neural Language Models}}},
	author = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
	date = {2020-01},
	eprint = {2001.08361},
	eprinttype = {arXiv},
	eprintclass = {cs, stat},
	doi = {10.48550/arXiv.2001.08361},
	abstract = {We study empirical scaling laws for language model performance on the cross-entropy loss. The loss scales as a power-law with model size, dataset size, and the amount of compute used for training, with some trends spanning more than seven orders of magnitude. Other architectural details such as network width or depth have minimal effects within a wide range. Simple equations govern the dependence of overfitting on model/dataset size and the dependence of training speed on model size. These relationships allow us to determine the optimal allocation of a fixed compute budget. Larger models are significantly more sample-efficient, such that optimally compute-efficient training involves training very large models on a relatively modest amount of data and stopping significantly before convergence.},
	organization = {arXiv},
	keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
	timestamp = {2024-09-11T14:44:08Z}
}

@article{keet2018IntroductionOntologyEngineering,
	file = {References/pdf/keet2018IntroductionOntologyEngineering.pdf},
	keywords = {ontology},
	year = {2018},
	title = {An Introduction to Ontology Engineering},
	author = {Keet, C Maria}
}

@book{kendall2019OntologyEngineering,
	file = {References/pdf/kendall2019OntologyEngineering.pdf},
	author = {Elisa F. Kendall and Deborah L. McGuinness},
	title = {Ontology Engineering},
	year = 2019,
	series = {Synthesis Lectures on the Semantic Web: Theory and
                  Technology},
	publisher = {Morgan {\&} Claypool Publishers},
	isbn = {978-3-031-79485-8},
	doi = {10.2200/S00834ED1V01Y201802WBE018},
	url = {https://doi.org/10.2200/S00834ED1V01Y201802WBE018},
	timestamp = {Thu, 19 Oct 2023 16:45:54 +0200},
	biburl = {https://dblp.org/rec/series/synthesis/2019Kendall.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{khadir2021OntologyLearningGrand,
	file = {References/pdf/khadir2021OntologyLearningGrand.pdf},
	title = {Ontology Learning: {{Grand}} Tour and Challenges},
	author = {Khadir, Ahlem Chérifa and Aliane, Hassina and Guessoum, Ahmed},
	date = {2021},
    year = 2021,
	journal = {Computer Science Review},
	volume = {39},
	pages = {100339},
	publisher = {Elsevier}
}

@misc{kommineni2024HumanExpertsMachines,
	file = {References/pdf/kommineni2024HumanExpertsMachines.pdf},
	author = {Vamsi Krishna Kommineni AND Birgitta König-Ries AND
                  Sheeba Samuel},
	title = {{From human experts to machines: An LLM supported
                  approach to ontology and knowledge graph
                  construction}},
	year = 2024,
	eprint = {2403.08345v1},
	primaryclass = {cs.CL},
	archiveprefix = {arXiv}
}

@article{liu2020ConceptPlacementUsing,
	file = {References/pdf/liu2020ConceptPlacementUsing.pdf},
	title = {Concept Placement Using {{BERT}} Trained by Transforming and Summarizing Biomedical Ontology Structure},
	author = {Liu, Hao and Perl, Yehoshua and Geller, James},
	date = {2020-12},
    year = 2020,
	journal = {Journal of Biomedical Informatics},
	volume = {112},
	pages = {103607},
	issn = {1532-0464},
	doi = {10.1016/j.jbi.2020.103607},
	abstract = {The comprehensive modeling and hierarchical positioning of a new concept in an ontology heavily relies on its set of proper subsumption relationships (IS-As) to other concepts. Identifying a concept's IS-A relationships is a laborious task requiring curators to have both domain knowledge and terminology skills. In this work, we propose a method to automatically predict the presence of IS-A relationships between a new concept and pre-existing concepts based on the language representation model BERT. This method converts the neighborhood network of a concept into “sentences” and harnesses BERT's Next Sentence Prediction (NSP) capability of predicting the adjacency of two sentences. To augment our method's performance, we refined the training data by employing an ontology summarization technique. We trained our model with the two largest hierarchies of the SNOMED CT 2017 July release and applied it to predicting the parents of new concepts added in the SNOMED CT 2018 January release. The results showed that our method achieved an average F1 score of 0.88, and the average Recall score improves slightly from 0.94 to 0.96 by using the ontology summarization technique.},
	langid = {english},
	keywords = {BERT,Machine learning,Natural language processing,Ontology placement,Ontology summarization,SNOMED CT},
	timestamp = {2024-07-25T09:06:38Z}
}

@misc{liu2023JailbreakingChatgptVia,
	file = {References/pdf/liu2023JailbreakingChatgptVia.pdf},
	author = {Yi Liu AND Gelei Deng AND Zhengzi Xu AND Yuekang Li
                  AND Yaowen Zheng AND Ying Zhang AND Lida Zhao AND
                  Tianwei Zhang AND Kailong Wang AND Yang Liu},
	title = {{Jailbreaking ChatGPT via Prompt Engineering: An
                  Empirical Study}},
	year = 2023,
	eprint = {2305.13860v2},
	primaryclass = {cs.SE},
	archiveprefix = {arXiv}
}

@article{lubani2019OntologyPopulationApproaches,
	file = {References/pdf/lubani2019OntologyPopulationApproaches.pdf},
	title = {Ontology Population: {{Approaches}} and Design Aspects},
	author = {Lubani, Mohamed and Noah, Shahrul Azman Mohd and Mahmud, Rohana},
	date = {2019},
        year = 2019,
	journal = {Journal of Information Science},
	volume = {45},
	number = {4},
	pages = {502--515},
	publisher = {SAGE Publications Sage UK: London, England}
}

@inbook{mai2024DoLlmsReally,
	file = {References/pdf/mai2024DoLlmsReally.pdf},
	title = {Do LLMs Really Adapt to Domains? An Ontology
                  Learning Perspective},
	year = 2024,
	author = {Mai, Huu Tan and Chu, Cuong Xuan and Paulheim,
                  Heiko},
	booktitle = {The Semantic Web – ISWC 2024},
	publisher = {Springer Nature Switzerland},
	isbn = 9783031778445,
	pages = {126–143},
	doi = {10.1007/978-3-031-77844-5_7},
	url = {http://dx.doi.org/10.1007/978-3-031-77844-5_7},
	ISSN = {1611-3349},
	month = nov
}

@article{mateiu2023OntologyEngineeringWith,
	file = {References/pdf/mateiu2023OntologyEngineeringWith.pdf},
	title = {Ontology Engineering with {{Large Language Models}}},
	author = {Mateiu, Patricia and Groza, Adrian},
	date = {2023-09},
    year = 2023,
	journal = {2023 25th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)},
	pages = {226--229},
	publisher = {IEEE},
	location = {Nancy, France},
	doi = {10.1109/SYNASC61333.2023.00038},
	abstract = {We tackle the task of enriching ontologies by automatically translating natural language (NL) into Description Logic (DL). Since Large Language Models (LLMs) are the best tools for translations, we fine-tuned a GPT-3 model to convert NL into OWL Functional Syntax. For fine-tuning, we designed pairs of sentences in NL and the corresponding translations. This training pairs cover various aspects from ontology engineering: instances, class subsumption, domain and range of relations, object properties relationships, disjoint classes, complements, or cardinality restrictions. The resulted axioms are used to enrich an ontology, in a human supervised manner. The developed tool is publicly provided as a Protégé plugin.},
	isbn = {9798350394122},
	timestamp = {2024-08-15T09:04:33Z}
}

@article{mcdaniel2019EvaluatingDomainOntologies,
	file = {References/pdf/mcdaniel2019EvaluatingDomainOntologies.pdf},
	title = {Evaluating Domain Ontologies: Clarification, Classification, and Challenges},
	author = {McDaniel, Melinda and Storey, Veda C},
	date = {2019},
        year = 2019,
	journal = {ACM Computing Surveys (CSUR)},
	volume = {52},
	number = {4},
	pages = {1--44},
	publisher = {ACM New York, NY, USA}
}

@inproceedings{mosbach2023FewShotFine,
	file = {References/pdf/mosbach2023FewShotFine.pdf},
	author = {Mosbach, Marius and Pimentel, Tiago and Ravfogel,
                  Shauli and Klakow, Dietrich and Elazar, Yanai},
	title = {Few-shot Fine-tuning vs. In-context Learning: A Fair
                  Comparison and Evaluation},
	year = 2023,
	booktitle = {Findings of the Association for Computational
                  Linguistics: ACL 2023},
	publisher = {Association for Computational Linguistics},
	doi = {10.18653/v1/2023.findings-acl.779},
	url = {http://dx.doi.org/10.18653/v1/2023.findings-acl.779}
}

@article{mungall2012UberonIntegrativeMulti,
	file = {References/pdf/mungall2012UberonIntegrativeMulti.pdf},
	title = {Uberon, an Integrative Multi-Species Anatomy Ontology},
	author = {Mungall, Christopher J. and Torniai, Carlo and Gkoutos, Georgios V. and Lewis, Suzanna E. and Haendel, Melissa A.},
	date = {2012-01},
	journal = {Genome Biology},
	volume = {13},
	number = {1},
	pages = {R5},
	issn = {1474-760X},
	doi = {10.1186/gb-2012-13-1-r5},
	abstract = {We present Uberon, an integrated cross-species ontology consisting of over 6,500 classes representing a variety of anatomical entities, organized according to traditional anatomical classification criteria. The ontology represents structures in a species-neutral way and includes extensive associations to existing species-centric anatomical ontologies, allowing integration of model organism and human data. Uberon provides a necessary bridge between anatomical structures in different taxa for cross-species inference. It uses novel methods for representing taxonomic variation, and has proved to be essential for translational phenotype analyses. Uberon is available at http://uberon.org},
	langid = {english},
	keywords = {Anatomy Ontology,Gene Ontology,Human Phenotype Ontology,Logical Definition,Open Biomedical Ontology},
	timestamp = {2024-09-12T13:50:12Z}
}

@misc{norouzi2024OntologyPopulationUsing,
	file = {References/pdf/norouzi2024OntologyPopulationUsing.pdf},
	author = {Sanaz Saki Norouzi AND Adrita Barua AND Antrea
                  Christou AND Nikita Gautam AND Andrew Eells AND
                  Pascal Hitzler AND Cogan Shimizu},
	title = {{Ontology Population using LLMs}},
	year = 2024,
	eprint = {2411.01612v1},
	primaryclass = {cs.AI},
	archiveprefix = {arXiv}
}

@misc{noy2001OntologyDevelopment101,
	file = {References/pdf/noy2001OntologyDevelopment101.pdf},
	keywords = {ontology},
	url = {https://protege.stanford.edu/publications/ontology\_development/ontology101.pdf},
	year = {2001},
	title = {Ontology Development 101: A guide to create your first ontology},
	author = {Noy, Natalya F and McGuiness, Deborah L and others}
}

@misc{openai2024HelloGpt4o,
	title = {Hello {{GPT-4o}}},
	author = {{OpenAI}},
	date = {2024},
    year = 2024,
	url = {https://openai.com/index/hello-gpt-4o/},
	urldate = {2024-09-12},
	abstract = {We're announcing GPT-4 Omni, our new flagship model which can reason across audio, vision, and text in real time.},
	langid = {american},
	timestamp = {2024-09-12T19:38:33Z}
}

@misc{openai2024IntroducingOpenaiO1,
	title = {Introducing {{OpenAI O1}}},
	author = {{OpenAI}},
	year = 2024,
	url = {https://openai.com/o1/}
}

@article{petasis2011OntologyPopulationEnrichment,
	file = {References/pdf/petasis2011OntologyPopulationEnrichment.pdf},
	title = {Ontology Population and Enrichment: {{State}} of the Art},
	author = {Petasis, Georgios and Karkaletsis, Vangelis and Paliouras, Georgios and Krithara, Anastasia and Zavitsanos, Elias},
	date = {2011},
        year = 2011,
	journal = {Knowledge-driven multimedia information extraction and ontology evolution: Bridging the semantic gap},
	pages = {134--166},
	publisher = {Springer}
}

@inproceedings{petroni2019LanguageModelsAs,
	file = {References/pdf/petroni2019LanguageModelsAs.pdf},
	title = {Language {{Models}} as {{Knowledge Bases}}?},
	booktitle = {Proceedings of the 2019 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} and the 9th {{International Joint Conference}} on {{Natural Language Processing}} ({{EMNLP-IJCNLP}})},
	author = {Petroni, Fabio and Rocktäschel, Tim and Riedel, Sebastian and Lewis, Patrick and Bakhtin, Anton and Wu, Yuxiang and Miller, Alexander},
	editor = {Inui, Kentaro and Jiang, Jing and Ng, Vincent and Wan, Xiaojun},
	date = {2019-11},
	pages = {2463--2473},
	publisher = {Association for Computational Linguistics},
	location = {Hong Kong, China},
	doi = {10.18653/v1/D19-1250},
	abstract = {Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as “fill-in-the-blank” cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.},
	timestamp = {2024-08-13T13:14:46Z}
}

@inproceedings{qiao2023ReasoningWithLanguage,
	file = {References/pdf/qiao2023ReasoningWithLanguage.pdf},
	author = {Qiao, Shuofei and Ou, Yixin and Zhang, Ningyu and
                  Chen, Xiang and Yao, Yunzhi and Deng, Shumin and
                  Tan, Chuanqi and Huang, Fei and Chen, Huajun},
	title = {Reasoning with Language Model Prompting: A Survey},
	year = 2023,
	booktitle = {Proceedings of the 61st Annual Meeting of the
                  Association for Computational Linguistics (Volume 1:
                  Long Papers)},
	publisher = {Association for Computational Linguistics},
	doi = {10.18653/v1/2023.acl-long.294},
	url = {http://dx.doi.org/10.18653/v1/2023.acl-long.294}
}

@inproceedings{roberts2020HowMuchKnowledge,
	file = {References/pdf/roberts2020HowMuchKnowledge.pdf},
	title = {How {{Much Knowledge Can You Pack Into}} the {{Parameters}} of a {{Language Model}}?},
	booktitle = {Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
	author = {Roberts, Adam and Raffel, Colin and Shazeer, Noam},
	editor = {Webber, Bonnie and Cohn, Trevor and He, Yulan and Liu, Yang},
	date = {2020-11},
	pages = {5418--5426},
	publisher = {Association for Computational Linguistics},
	location = {Online},
	doi = {10.18653/v1/2020.emnlp-main.437},
	abstract = {It has recently been observed that neural language models trained on unstructured text can implicitly store and retrieve knowledge using natural language queries. In this short paper, we measure the practical utility of this approach by fine-tuning pre-trained models to answer questions without access to any external context or knowledge. We show that this approach scales with model size and performs competitively with open-domain systems that explicitly retrieve answers from an external knowledge source when answering questions. To facilitate reproducibility and future work, we release our code and trained models.},
	timestamp = {2024-08-13T13:15:17Z}
}

@misc{schulhoff2024PromptReportSystematic,
	file = {References/pdf/schulhoff2024PromptReportSystematic.pdf},
	author = {Sander Schulhoff AND Michael Ilie AND Nishant
                  Balepur AND Konstantine Kahadze AND Amanda Liu AND
                  Chenglei Si AND Yinheng Li AND Aayush Gupta AND
                  HyoJung Han AND Sevien Schulhoff AND Pranav Sandeep
                  Dulepet AND Saurav Vidyadhara AND Dayeon Ki AND
                  Sweta Agrawal AND Chau Pham AND Gerson Kroiz AND
                  Feileen Li AND Hudson Tao AND Ashay Srivastava AND
                  Hevander Da Costa AND Saloni Gupta AND Megan
                  L. Rogers AND Inna Goncearenco AND Giuseppe Sarli
                  AND Igor Galynker AND Denis Peskoff AND Marine
                  Carpuat AND Jules White AND Shyamal Anadkat AND
                  Alexander Hoyle AND Philip Resnik},
	title = {{The Prompt Report: A Systematic Survey of Prompt
                  Engineering Techniques}},
	year = 2024,
	eprint = {2406.06608v6},
	primaryclass = {cs.CL},
	archiveprefix = {arXiv}
}

@misc{shaya2012AstronomyOntology,
	title = {Astronomy {{Ontology}}},
	author = {Shaya, Edward},
	date = {2012},
        year = 2012,
	url = {https://www.astro.umd.edu/~eshaya/astro-onto/ontologies/astronomy.html},
	urldate = {2024-11-20},
	timestamp = {2024-11-20T14:00:28Z}
}

@article{snijder2024AdvancingOntologyAlignment,
	file = {References/pdf/snijder2024AdvancingOntologyAlignment.pdf},
	title = {Advancing {{Ontology Alignment}} in the {{Labor Market}}: {{Combining Large Language Models}} with {{Domain Knowledge}}},
	shorttitle = {Advancing {{Ontology Alignment}} in the {{Labor Market}}},
	author = {Snijder, Lucas L. and Smit, Quirine T. S. and family=Boer, given=Maaike H. T., prefix=de, useprefix=true},
	date = {2024-05},
	journal = {Proceedings of the AAAI Symposium Series},
	volume = {3},
	number = {1},
	pages = {253--262},
	issn = {2994-4317},
	doi = {10.1609/aaaiss.v3i1.31208},
	abstract = {One of the approaches to help the demand and supply problem in the labor market domain is to change from degree-based hiring to skill-based hiring. The link between occupations, degrees and skills is captured in domain ontologies such as ESCO in Europe and O*NET in the US. Several countries are also building or extending these ontologies. The alignment of the ontologies is important, as it should be clear how they all relate. Aligning two ontologies by creating a mapping between them is a tedious task to do manually, and with the rise of generative large language models like GPT-4, we explore how language models and domain knowledge can be combined in the matching of the instances in the ontologies and in finding the specific relation between the instances (mapping refinement). We specifically focus on the process of updating a mapping, but the methods could also be used to create a first-time mapping. We compare the performance of several state-of-the-art methods such as GPT-4 and fine-tuned BERT models on the mapping between ESCO and O*NET and ESCO and CompetentNL (the Dutch variant) for both ontology matching and mapping refinement. Our findings indicate that: 1) Match-BERT-GPT, an integration of BERT and GPT, performs best in ontology matching, while 2) TaSeR outperforms GPT-4, albeit marginally, in the task of mapping refinement. These results show that domain knowledge is still important in ontology alignment, especially in the updating of a mapping in our use cases in the labor domain.},
	copyright = {Copyright (c) 2024 Association for the Advancement of Artificial Intelligence},
	langid = {english},
	keywords = {O*NET},
	timestamp = {2024-09-16T11:59:33Z}
}

@inproceedings{wang2024CanLargeLanguage,
	file = {References/pdf/wang2024CanLargeLanguage.pdf},
	author = {Wang, Keyu and Qi, Guilin and Li, Jiaqi and Zhai,
                  Songlin},
	title = {Can Large Language Models Understand DL-Lite
                  Ontologies? An Empirical Study},
	year = 2024,
	booktitle = {Findings of the Association for Computational
                  Linguistics: EMNLP 2024},
	publisher = {Association for Computational Linguistics},
	pages = {2503–2519},
	doi = {10.18653/v1/2024.findings-emnlp.141},
	url = {http://dx.doi.org/10.18653/v1/2024.findings-emnlp.141}
}

@misc{white2023PromptPatternCatalog,
	file = {References/pdf/white2023PromptPatternCatalog.pdf},
	author = {Jules White AND Quchen Fu AND Sam Hays AND Michael
                  Sandborn AND Carlos Olea AND Henry Gilbert AND
                  Ashraf Elnashar AND Jesse Spencer-Smith AND Douglas
                  C. Schmidt},
	title = {{A Prompt Pattern Catalog to Enhance Prompt
                  Engineering with ChatGPT}},
	year = 2023,
	eprint = {2302.11382v1},
	primaryclass = {cs.SE},
	archiveprefix = {arXiv}
}

@inproceedings{wilson2022OntologyQualityEvaluation,
	file = {References/pdf/wilson2022OntologyQualityEvaluation.pdf},
	title = {Ontology Quality Evaluation Methodology},
	booktitle = {International Conference on Computational Science and Its Applications},
	author = {Wilson, R Shyama I and Goonetillake, Jeevani S and Ginige, Athula and Indika, Walisadeera Anusha},
	date = {2022},
        year = 2022,
	pages = {509--528},
	publisher = {Springer}
}

@article{wilson2023ConceptualModelOntology,
	file = {References/pdf/wilson2023ConceptualModelOntology.pdf},
	title = {A Conceptual Model for Ontology Quality Assessment: {{A}} Systematic Review},
	shorttitle = {A Conceptual Model for Ontology Quality Assessment},
	author = {Wilson, R.S.I. and Goonetillake, J.S. and Indika, W.A. and Ginige, Athula},
	editor = {Gangemi, Aldo},
	date = {2023-12},
        year = 2023,
	journal = {Semantic Web},
	volume = {14},
	number = {6},
	pages = {1051--1097},
	issn = {22104968, 15700844},
	doi = {10.3233/SW-233393},
	abstract = {With the continuous advancement of methods, tools, and techniques in ontology development, ontologies have emerged in various fields such as machine learning, robotics, biomedical informatics, agricultural informatics, crowdsourcing, database management, and the Internet of Things. Nevertheless, the nonexistence of a universally agreed methodology for specifying and evaluating the quality of an ontology hinders the success of ontology-based systems in such fields as the quality of each component is required for the overall quality of a system and in turn impacts the usability in use. Moreover, a number of anomalies in definitions of ontology quality concepts are visible, and in addition to that, the ontology quality assessment is limited only to a certain set of characteristics in practice even though some other significant characteristics have to be considered for the specified use-case. Thus, in this research, a comprehensive analysis was performed to uncover the existing contributions specifically on ontology quality models, characteristics, and the associated measures of these characteristics. Consequently, the characteristics identified through this review were classified with the associated aspects of the ontology evaluation space. Furthermore, the formalized definitions for each quality characteristic are provided through this study from the ontological perspective based on the accepted theories and standards. Additionally, a thorough analysis of the extent to which the existing works have covered the quality evaluation aspects is presented and the areas further to be investigated are outlined.},
	langid = {english},
	keywords = {In Progress,Review},
	timestamp = {2024-08-01T09:32:28Z}
}

@article{wong2012OntologyLearningText,
	file = {References/pdf/wong2012OntologyLearningText.pdf},
	title = {Ontology Learning from Text: {{A}} Look Back and into the Future},
	author = {Wong, Wilson and Liu, Wei and Bennamoun, Mohammed},
	date = {2012},
        year = 2012,
	journal = {ACM computing surveys (CSUR)},
	volume = {44},
	number = {4},
	pages = {1--36},
	publisher = {ACM New York, NY, USA}
}

@inproceedings{yang2024LlmSupportedApproach,
	file = {References/pdf/yang2024LlmSupportedApproach.pdf},
	author = {Yang, Hang and Xiao, Liang and Zhu, Rujun and Liu,
                  Ziji and Chen, Jianxia},
	title = {An LLM supported approach to ontology and knowledge
                  graph construction},
	year = 2024,
	booktitle = {2024 IEEE International Conference on Bioinformatics
                  and Biomedicine (BIBM)},
	publisher = {IEEE},
	month = dec,
	pages = {5240–5246},
	doi = {10.1109/bibm62325.2024.10822222},
	url = {http://dx.doi.org/10.1109/BIBM62325.2024.10822222}
}

@misc{zhao2023SurveyLargeLanguage,
	file = {References/pdf/zhao2023SurveyLargeLanguage.pdf},
	title = {A {{Survey}} of {{Large Language Models}}},
	author = {Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and Du, Yifan and Yang, Chen and Chen, Yushuo and Chen, Zhipeng and Jiang, Jinhao and Ren, Ruiyang and Li, Yifan and Tang, Xinyu and Liu, Zikang and Liu, Peiyu and Nie, Jian-Yun and Wen, Ji-Rong},
	date = {2023-11},
        year = 2023,
	eprint = {2303.18223},
	eprinttype = {arXiv},
	eprintclass = {cs},
	abstract = {Ever since the Turing Test was proposed in the 1950s, humans have explored the mastering of language intelligence by machine. Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable artificial intelligence (AI) algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pretraining Transformer models over large-scale corpora, showing strong capabilities in solving various natural language processing (NLP) tasks. Since the researchers have found that model scaling can lead to an improved model capacity, they further investigate the scaling effect by increasing the parameter scale to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement, but also exhibit some special abilities (e.g., incontext learning) that are not present in small-scale language models (e.g., BERT). To discriminate the language models in different parameter scales, the research community has coined the term large language models (LLM) for the PLMs of significant size (e.g., containing tens or hundreds of billions of parameters). Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT (a powerful AI chatbot developed based on LLMs), which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. Considering this rapid technical progress, in this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Furthermore, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions. This survey provides an up-to-date review of the literature on LLMs, which can be a useful resource for both researchers and engineers.},
	langid = {english},
	organization = {arXiv},
	keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
	timestamp = {2024-08-13T13:39:27Z}
}

@article{zhou2007OntologyLearningState,
	file = {References/pdf/zhou2007OntologyLearningState.pdf},
	title = {Ontology Learning: State of the Art and Open Issues},
	author = {Zhou, Lina},
	date = {2007},
        year = 2007,
	journal = {Information Technology and Management},
	volume = {8},
	pages = {241--252},
	publisher = {Springer}
}

@article{sahbi2025semantic,
  title={Semantic vs. LLM-based approach: A case study of KOnPoTe vs. Claude for ontology population from French advertisements},
  author={Sahbi, Aya and Alec, C{\'e}line and Beust, Pierre},
  journal={Data \& Knowledge Engineering},
  volume={156},
  pages={102392},
  year={2025},
  publisher={Elsevier}
}

@inproceedings{kandpal2023LargeLanguageModels,
	author = {Nikhil Kandpal and Haikang Deng and Adam Roberts and
                  Eric Wallace and Colin Raffel},
	title = {Large Language Models Struggle to Learn Long-Tail
                  Knowledge},
	year = 2023,
	booktitle = {International Conference on Machine Learning, {ICML}
                  2023, 23-29 July 2023, Honolulu, Hawaii, {USA}},
	pages = {15696-15707},
	url = {https://proceedings.mlr.press/v202/kandpal23a.html},
	timestamp = {Mon, 28 Aug 2023 17:23:08 +0200},
	biburl = {https://dblp.org/rec/conf/icml/KandpalDRWR23.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}

@article{davies1979ClusterSeparationMeasure,
  author={Davies, David L. and Bouldin, Donald W.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={A Cluster Separation Measure}, 
  year={1979},
  volume={PAMI-1},
  number={2},
  pages={224-227},
  keywords={Dispersion;Density measurement;Algorithm design and analysis;Clustering algorithms;Partitioning algorithms;Multidimensional systems;Data analysis;Performance analysis;Humans;Missiles;Cluster;data partitions;multidimensional data analysis;parametric clustering;partitions;similarity measure},
  doi={10.1109/TPAMI.1979.4766909}}

@misc{openai2024EmbeddingModels,
	author = {OpenAI},
	title = {{N}ew embedding models and {A}{P}{I} updates --- openai.com},
	howpublished = {\url{https://openai.com/index/new-embedding-models-and-api-updates/}},
	year = {25-01-2024},
	note = {[Accessed 06-05-2025]},
}

@article{van2008VisualizingData,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={Journal of machine learning research},
  volume={9},
  number={11},
  year={2008}
}

@article{wang2024Advanced,
  title={Do advanced language models eliminate the need for prompt engineering in software engineering?},
  author={Wang, Guoqing and Sun, Zeyu and Gong, Zhihao and Ye, Sixiang and Chen, Yizhou and Zhao, Yifan and Liang, Qingyuan and Hao, Dan},
  journal={arXiv preprint arXiv:2411.02093},
  year={2024}
}

@article{nori2024Medprompt,
  title={From medprompt to o1: Exploration of run-time strategies for medical challenge problems and beyond},
  author={Nori, Harsha and Usuyama, Naoto and King, Nicholas and McKinney, Scott Mayer and Fernandes, Xavier and Zhang, Sheng and Horvitz, Eric},
  journal={arXiv preprint arXiv:2411.03590},
  year={2024}
}

@article{guo2025DeepSeek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@article{grattafiori2024Llama,
  title={The llama 3 herd of models},
  author={Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}
@article{zhang2023Instruction,
  title={Instruction tuning for large language models: A survey},
  author={Zhang, Shengyu and Dong, Linfeng and Li, Xiaoya and Zhang, Sen and Sun, Xiaofei and Wang, Shuhe and Li, Jiwei and Hu, Runyi and Zhang, Tianwei and Wu, Fei and others},
  journal={arXiv preprint arXiv:2308.10792},
  year={2023}
}

@article{levenshtein1965BinaryCodesCapable,
	title = {Binary codes capable of correcting deletions, insertions, and reversals},
	author = {Vladimir I. Levenshtein},
	journal = {Soviet physics. Doklady},
	year = {1965},
	volume = {10},
	pages = {707-710},
	url = {https://api.semanticscholar.org/CorpusID:60827152}
}


@InProceedings{auer2007DbpediaNucleusWeb,
	file = {References/pdf/auer2007DbpediaNucleusWeb.pdf},
	author = {S{\"{o}}ren Auer and Christian Bizer and Georgi
                  Kobilarov and Jens Lehmann and Richard Cyganiak and
                  Zachary G. Ives},
	title = {DBpedia: {A} Nucleus for a Web of Open Data},
	year = 2007,
	booktitle = {The Semantic Web, 6th International Semantic Web
                  Conference, 2nd Asian Semantic Web Conference,
                  {ISWC} 2007 + {ASWC} 2007, Busan, Korea, November
                  11-15, 2007},
	pages = {722-735},
	doi = {10.1007/978-3-540-76298-0\_52},
	url = {https://doi.org/10.1007/978-3-540-76298-0\_52},
	crossref = {DBLP:conf/semweb/2007},
	timestamp = {Mon, 03 Mar 2025 21:21:20 +0100},
	biburl = {https://dblp.org/rec/conf/semweb/AuerBKLCI07.bib},
	bibsource = {dblp computer science bibliography,
                  https://dblp.org}
}