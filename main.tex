% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{hyperref}
\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
\usepackage{float}
\usepackage{subcaption}
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%\urlstyle{rm}
%
\usepackage{soul}
\usepackage[dvipsnames]{xcolor}
\usepackage[commandnameprefix=always,todonotes={textsize=footnotesize}]{changes} % Add 'final' for submission
\sethighlightmarkup{\IfIsColored{{\sethlcolor{authorcolor!30}\hl{#1}}}{#1}}
\definechangesauthor[name={Upal Bhattachara}, color=Violet]{UB}

\usepackage[numbers,sort&compress]{natbib}
\bibliographystyle{splncs04nat}

\usepackage{amsmath}

\begin{document}
%
\title{Ontology Population Using LLMs: Which Factors Matter?}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Upal Bhattacharya\inst{1}\orcidID{0000-0002-0877-7063}\and
        Maaike de Boer\inst{2}\orcidID{0000-0002-2775-8351} \and
        Sergey Sosnovsky\inst{1}\orcidID{0000-0001-8023-1770}}

\authorrunning{U. Bhattacharya et al.}
% % First names are abbreviated in the running head.
% % If there are more than two authors, 'et al.' is used.
% %
\institute{
    Department of Information and Computing Sciences, Utrecht Univerisity, Princetonplein 5, 3584 CC, Utrecht, The Netherlands \\
    \email{u.bhattacharya@uu.nl, s.a.sosnovsky@uu.nl} \and
    Department Data Science, TNO, Anna van Buerenplein 1, 2595 DA, Den Haag, The Netherlands \\ 
    \email{maaike.deboer@tno.nl}
    }
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
The abstract should briefly summarize the contents of the paper in
150--250 words.

\keywords{First keyword  \and Second keyword \and Another keyword.}
\end{abstract}
%
%
%
\section{Introduction}
\label{sec:introduction}

\section{Related Work}
\label{sec:related-work}

\section{Factors of Influence}
% \chcomment[id=UB]{\textit{Might need to change Section Title.}}
\label{sec:factors}

The factors governing LLM-supported ontology population can be categorized
into two groups: Ontology factors and LLM factors. We provide an overview of
the relevant factors for each group, highlighting their relevance in
LLM-supported ontology population. Figure \ref{fig:variation-overview}
provides an overview of the factors of each group.

\begin{figure}[H]
\includegraphics[width=\textwidth]{assets/factor-overview.drawio.pdf}
\caption{Overview of Ontology and LLM factors influencing LLM-supported
Ontology Population. Dashed boxes are not investigated in the present
study} \label{fig:variation-overview}
\end{figure}

\subsection{Ontology Factors}
\label{subsec:ontology-factors}

Ontologies vary greatly depending on the complexities of the modeled domain
and the design choices taken by ontology engineers and domain experts
\citep{noy2001OntologyDevelopment101}. Our categorization of ontology factors
draws inspiration from the Ontology Learning Layer Cake
\citep{gangemi2005OntologyEvaluationValidation} with additional included
factors that are not captured by it.

\subsubsection{Scope:}
\label{subsubsec:ont-factor-scope}

The scope of an ontology defines the level of specificity and abstraction of
its entities and its structural design. Ontologies can be \textbf{upper-level}
ontologies that define abstractions enabling integration of heterogeneous
knowledge across different domains
\citep{mascardi2007ComparisonUpperOntologies} or of a particular
\textbf{domain} itself e.g. the Gene Ontology (GO)
\cite{ashburner2000GeneOntologyTool} designed using the principles provided by
an upper ontology. The scope of ontologies test the semantic abilities of
LLMs. Upper ontologies challenge LLMs to understand abstractions effectively
requiring them to extract the ontological semantics of entities whereas domain
ontologies require LLMs to more directly apply their 'understanding' of
entities. The former requires LLMs to `take a step back' from the actual
content and recognize general patterns while the latter requires understanding
patterns based on the content itself.

\subsubsection{Metrics:}
\label{subsubsec:ont-factor-metrics}

% Overall

\citet{hlomani2014ApproachesMethodsMetrics} highlight several
\textbf{structural} and \textbf{functional} metrics for evaluating
ontologies.
\begin{itemize}
\item Structural metrics evaluate the structural complexity of an ontology in
  terms of its size, breadth, depth and dispersion
  \citep{hlomani2014ApproachesMethodsMetrics}. The structure of an ontology
  highlights the semantics of the underlying domain or scope. The breadth and
  size of an ontology in terms of its entity count is an indicator of the
  vastness of its scope. Ontologies with large depth reflect domains with
  knowledge of high granularity while those with greater dispersion represent
  domains with several closely-related concepts (siblings). Structural nuances
  test the ability of LLMs to identify and populate domains of varying
  enormity and relational complexity.
\item Functional measures test the intended use of an ontology
  \citep{gangemi2005OntologyEvaluationValidation}. They evaluate the logical
  consistency and comprehensiveness of an ontology as a specification of a
  domain and its conceptualization. Measures likes completeness, conciseness,
  coverage and clarity \citep{hlomani2014ApproachesMethodsMetrics} indicate
  functional competency of an ontology in modelling its domain. While these
  measures are approximations of the effectiveness of the modelling of the
  domain, they can help highlight whether functional adequacy of an ontology
  influences the ability of an LLM to identify its assertions.
\end{itemize}

\subsubsection{Entity Labels:}
\label{subsubsec:ont-factor-entity-labels}

The naming of entites in an ontology is largely governed by conventions
followed in the domain of interest and by any upper ontologies used as
reference. Through their pre-training, LLMs exhibit impressive natural
language understanding and generation capabilities. The lexical semantics
learnt by LLMs are known to exhibit impressive performance on tasks of sense
distinction and semantic equivalence
\citep{hayashi2025EvaluatingLlmsCapability,petersen2023LexicalSemanticsWith}.
In terms of ontology population, LLMs are required to apply their lexical
sense of concept and individual labels to effectively identify
assertions. Variation in entity label naming highlights the parity between the
ontological semantics of the entities and the learnt lexical semantics of LLMs
for their labels. This parity is crucial for effective ontology population. As
most LLMs employ subword tokenization like Byte Pair Encoding (BPE)
\citep{sennrich2016NeuralMachineTranslation} for understanding prompts and
generating texts, evaluation over entity labels highlights whether LLMs are
able to effectively utilize lexical semantics or resort to more conventional
string edit-distance-based senses for performing ontology population.

\subsubsection{Taxonomy:}
\label{subsubsec:ont-factor-taxonomy}

The taxonomy of an ontology is the pivotal backbone structure that defines the
hierarchy of concepts in a domain. While ontology population is concerned
primarily with identifying instances for concepts, it requires understanding
the granularity of the taxonomy to identify the correct concept for a new
individual assertion. Through LLM-supported ontology population, we can
investigate whether LLMs are capable of understanding the taxonomy of an
ontology and how new individuals are to be placed within that taxonomy.

\subsubsection{Non-hierarchical Relations:}
\label{subsubsec:ont-factor-other-relations}

Apart from hierarchical relations, ontologies possess a wide variety of other
relations that describe other phenomena of a domain. Parthood, associative
relations and attribute relation properties comprise a large portion of
ontological relations. Such relations add complexity to the task of ontology
population, requiring care to avoid asserting new individuals with closely
related concepts e.g. asserting `Red' as an instance of the concept `Wine' in
the Wine Ontology \citep{noy2001OntologyDevelopment101} instead of an
attribute value of `WineColor' that is associated with different classes of
wine with the relation `hasColor'. Analysing whether LLMs are susceptible to
such pitfalls when populating ontologies can provide insight into their
ability to accurately apply a sense distinction in the context of ontologies.

\subsubsection{Attributes:}
\label{subsubsec:ont-factor-attributes}

Closely related to non-hierarchical relations, attributes and properties pose
challenges of ontology sense distinction for LLMs enabling investigation of
their ability to distinguish attributes and data classes from core concepts of
the domain.

\subsubsection{Axioms:}
\label{subsubsec:ont-factor-axioms}

Axioms are the fundamental underlying principles that define the theory and
capabilities of an ontology. Axioms of logic, classes, individuals, properties
and classes define what is true in an ontology. They are logical
abstractions of the behaviour exhibited by the entities of an ontology in the
other layers of the Ontology Learning Layer Cake. While ontology population
itself does not strongly concern itself with the axioms of an ontology,
behaviour observed over the other factors observed for LLM-supported
ontology population provide indicators of the compliance of LLM-based
reasoning for ontology population with ontology axioms.

\subsection{LLM Factors}
\label{subsec:llm-factors}

The capabilities of LLMs in natural language generation and understanding has
led to immense growth in research about their abilities and limitations. As an
ever-growing field, factors regularly change with new research. We categorize
LLM factors based on already well-established factors in LLM research.

\subsubsection{Choice of LLM:}
\label{subsubsec:llm-factor-choice}

The number of available LLMs is growing constantly with HuggingFace
\cite{wolf2019HuggingfacesTransformersState} now reporting over $2.2$ million
models. The choice of an LLM is one of the first factors influencing ontology
population. Choosing an appropriate LLM is governed by several additional
factors:
\begin{itemize}
\item The emergent abilities of LLMs grows with \textbf{model size}
  \cite{chalmers2023CouldLargeLanguage}. Thus, it may be often desirable to
  use larger LLMs for ontology population. However, the choice of an LLM based
  on model size is closely related to other LLM factors. For domains in the
  long-tail of the pre-training corpus, LLMs may struggle with proper ontology
  population \cite{kandpal2023LargeLanguageModels}. In such situations,
  fine-tuning is known to outperform in-context learning
  \cite{liu2022FewShotParameter}. Owing to their size, larger LLMs may be
  difficult to fine-tune due to computational resource limitations. In such
  cases, smaller LLMs offer performant alternatives for
  fine-tuning.
\item The \textbf{availability} of model weights enables task-specific
  fine-tuning and further analysis of performance. However, commercially
  available state-of-the-art LLMs operate as `black-boxes' that prevents
  further analysis of performance. In contrast, open-source and open-weight
  models provide model alternatives that can be fine-tuned for long-tail
  domain-specific ontology population. While commercially-available LLMs are
  known to perform better \cite{bommasani2023HolisticEvaluationLanguage},
  comparing performance of open models against commercial LLMs fosters
  research to bridge the gap in performance across all natural language
  processing (NLP) tasks.
\item LLMs are capable of handling a wide variety of tasks. However, they do
  struggle with \textbf{specialization} in reasoning. LLM-supported ontology
  population requires an LLM to understand and reason over concepts, their
  hierarchy and assign new instances. Investigation of performance of
  general-purpose LLMs versus reasoning-specific LLMs highlights the
  significance of LLM reasoning capabilities to identify correct
  assertions. It shows whether simple textual pre-training and instruction
  fine-tuning is sufficient for ontology population or additional reasoning
  abilities are necessary to accomplish the task.
\end{itemize}

\subsubsection{Task:}
\label{subsubsec:llm-factor-task}
LLMs are used for a broad set of NLP-specific tasks. They are `prompted' with
a task description and provided guidelines to generate responses that coincide
with the task-specific responses desired. As models that use in-context
learning to understand the task from the input prompt, the formulation of the
task is a factor for LLM-supported ontology population. Formulation as a
classification or a retrieval task can lead to varied performance exhibited by
the LLM.

\subsubsection{Approach:}
\label{subsubsec:llm-factor-approach}

LLMs can be utilized as instruction-following agents, fine-tuned for a
specific objective or coupled with a data store to facilitate
data-substantiated text generation with each approach having its own merits
and demerits. Different approaches highlight the level of context, task
adaptation and data grounding is required by LLMs for ontology population.
\begin{itemize}
\item A significant portion of LLM approaches are focused on
  \textbf{prompting} strategies. Prompt engineering has itself become an area
  of research \cite{liu2023JailbreakingChatgptVia,mosbach2023FewShotFine,
    qiao2023ReasoningWithLanguage,schulhoff2024PromptReportSystematic,
    white2023PromptPatternCatalog} due to its openness and lack of consensus
  apart from general
  principles\footnote{\href{https://help.openai.com/en/articles/
      6654000-best-practices-for-prompt-engineering-with-the-openai-api}{Best
      Practices for Prompt Engineering with OpenAI API}} for structuring
  prompts. Taking advantage of the in-context learning capabilities of LLMs,
  prompting methods focus on strategies that require the LLM to perform a task
  without any example (zero-shot), through the provision of providing
  illustrative examples to facilitate better understanding of the task
  (few-shot) or by sequential prompting by breaking down a task into a
  sequence of steps allowing LLMs to reason better (Chain-of-Thought
  \cite{wei2022ChainThoughtPrompting}). These strategies indicate the
  relevance of the pre-learnt knowledge of LLMs for ontologies and their
  ability to adapt when given additional context.
\item While LLMs are capable of performing several tasks `as-is',
  task-specific \textbf{fine-tuning} provides an effective strategy to improve
  performance when in-context learning is unable to yield improvements
  \cite{liu2022FewShotParameter}.
\item \cite{huang2024LargeLanguageModel}
  
  \cite{lewis2020RetrievalAugmentedGeneration})
\end{itemize}

\subsubsection{Domain Context:}
\label{subsubsec:llm-factor-domain-context}

\subsubsection{Response Variation:}
\label{subsubsec:llm-factor-response-variation}

\subsection{Interplay of Factors}
\label{subsec:factor-interplay}

\section{Experimentation}
\label{sec:experimentation}

\subsection{Formulation}
\label{subsec:formulation}

{\parindent0pt % disable indentation for formulation
Following \citet{hlomani2014ApproachesMethodsMetrics}, we consider the task
of ontology population as part of the ontology learning pipeline.  We define
an ontology $O$ as a 4-tuple:
\begin{align}
  O = \langle C, H, R, A \rangle
\end{align}

where, \newline $C$ is the set of Concepts $\{c\}$; \newline $H$ is the set of
taxonomical/hierarchical (`is a') relations over $C$; \newline $R$ is the set
of non-taxonomical relations over $C$ and; \newline $A$ is a set of axioms
\newline

Let $t$ be a term to be mapped as an individual to a concept in $C$ \newline
Then the task of ontology population is:
\begin{equation}
  f(t;O)^{Ontology}_{Population} =\ \{c_i \mid c_i \in C\ ;\ c_i \subseteq c_{i+1}\ ;\ t \in \Sigma_{c_1}\ ;\ 1 \leq i \leq d \}
\end{equation}
where, \newline $d$ is an integer value equal to the depth of the concept
$c_1$ in $O$ \newline $\subseteq$ denotes the `subclass of' or `is a' relation
(taxonomical relations of $O$ i.e. $H$); \newline $c_1$ is the directly
asserted concept of the term $t$ and,\newline $\Sigma_{c_1}$ is the extension
\cite{hlomani2014ApproachesMethodsMetrics} of $c_1$ (i.e. set of
asserted individuals)
\section{Results and Discussion}
\label{sec:results}

\section{Conclusion}
\label{sec:conclusion}


\bibliography{bibliography}
\end{document}
